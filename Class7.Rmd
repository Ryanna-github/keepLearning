---
title: "Class7"
author: "renyan"
date: "2019年11月29日"
output: 
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
---

```{r, include = F}
library(prettydoc)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

机器学习实操重要函数：


- 数据集分割：```caret``` 中
  - ```createDataPartition()``` 留出法分割数据集
  - ```createFolds()``` 交叉验证
  - ```createResample()``` Bootstrap
  -```createTimeSlices()``` 分割时间数据
  
- ```preProcess()``` 中位数，k 临近，Bagging 处理缺失值
- ```nearZeroVar()``` 寻找近零方差变量，返回一组数
- ```findCorrelation()```找到高度共线性的变量

- 模型调参：```trainControl()```, ```train()```还不太会...



```{r, warning = F, message = F}
library(ggplot2)
library(caret)
library(lattice)
library(randomForest)
library(RANN)
```


# 数据导入

```{r}
setwd("C:/Users/lenovo/Desktop/RYaan/R/class_software/Notes")
```

```{r}
dat <- read.csv("../Data/相亲数据2.csv", encoding = 'GBK2312')
head(dat)
```


# 数据预处理：数据分割

数据分割，划分出测试集和训练集

## 留出法

- 将样本划分为两个互斥的子集，一个训练集一个测试积极
- caret包，```createDataPartition()``` 可以将数据划分
- 注意设置随机数种子为了保证可重复性


```{r}
set.seed(1234)
# 后两个参数此处为默认值
# list 参数表示输出形式，T 输出列表，否则以 matrix 格式输出
trainIndex = createDataPartition(dat$'决定', p = 0.8, list = FALSE, times = 1)
datTrain <- dat[trainIndex,]
datTest <- dat[-trainIndex,]
# 测试集和训练集中标记的占比
table(datTrain$'决定')/nrow(datTrain)
table(datTest$'决定')/nrow(datTest)
```


## 交叉验证法

- 将原始数据分成 k 组，通常均分，每次其中一组作为测试集，其他都是训练集。
- k = 10 常见。
- ```createFolds()``` 函数将数据都编上组号。


```{r}
index <- createFolds(dat$'决定', k = 3, list = FALSE, returnTrain = TRUE)
index
testIndex = which(index == 1)
# 训练集
datTraincv = dat[-testIndex, ]
# 测试集
datTestcv = dat[testIndex, ]
```


## Bootstrap 法

- 实现又放回的抽样，适合数据量比较少的情况
- ```createResample()``` 中，```times``` 参数用于设定生成几份随机样本

```{r}
set.seed(1234)
# 抽取三次样本
createResample(dat$'决定', times = 3, list = FALSE)
```

## 分割时间数据

- ```createTimeSlices()``` 函数

```{r}
growdata = read.csv("../Data/time.csv")
head(growdata)
```


```{r}
# initialWindows 在训练集中原本的连续型变量的个数
# horizon 测试集中原本的连续型变量
timeSlices <- createTimeSlices(1:nrow(growdata),
                               initialWindow = 5, horizon = 2, fixedWindow = TRUE)
timeSlices
```


# 数据预处理

## 处理缺失值

- ```preProcess()```  函数三种方法
  - k 临近方法：会利用训练集的均值和标准差对原始数据进行标注化
  - Bagging 树集成方法，对缺失值的填补更权威但是效率比较低
  - 中位数法：中值插补，速度快最简单但是不准确，一组数据插补的值是一样的：用训练集的中位数代替缺失值
  
- ```mice``` 包：多重插补法

  - 基于蒙特克罗方法

多重插补法


### 中位数法
- 用训练集的中位数代替缺失值
- 适用样本比较均匀的情况

```{r}
imputation_k <- preProcess(datTrain, method = 'medianImpute')
imputation_k
datTrain1 = predict(imputation_k, datTrain)
datTeset1 <- predict(imputation_k, datTest)
datTeset1
median(datTrain$'智力', na.rm = T)
```

### k 近邻方法

- 使用训练集的均值和标准差进行标准化，插补的是标准化数值，需要进行还原

```{r}
library(RANN)
imputation_k <- preProcess(datTrain, method = 'knnImpute')
datTrain1 = predict(imputation_k, datTrain)
datTeset1 <- predict(imputation_k, datTest)
datTrain$'智力' <- datTrain1$'智力' * sd(datTrain$'智力', na.rm = T) + mean(datTrain$'智力', na.rm = T)
datTest$'智力' <- datTest1$'智力' * sd(datTest$'智力', na.rm = T) + mean(datTest$'智力', na.rm = T)
# 其中 na.rm = T 会移除所有的 na
```


## 处理 0 方差变量
- 有两列长得基本一模一样的变化，这样的数据没有什么作用，从建模的角度看可以看做常数  
- 零方差、近零方差变量
- ```nearZeroVar()``` 寻找近零方差变量，返回的是变量的列编号向量
  
```{r}
dim(datTrain)
nzv = nearZeroVar(datTrain)
nzv
datTrain = datTrain[, -nzv]
```

## 处理高度线性相关变量
  - 性别和对方性别
  - ```findCorrelation()```，找到高度共线性的变量，并且给出删除建议 函数：找到高度线性相关的比阿尼朗，并给出建议删除的变量
  - 前提条件，数据不可以有缺失，只能包含数值型变量的 dataframe 或者 matrix，不可以有分类变量，只能是数值型变量
  
```{r}
# 数据中不能有 na
# 去除名字和对方名字两个变量
datTrain1 <- datTrain[, -c(1, 6)]
# 先找到相关镇进行初步观察
# cor 计算的是简单相关系数
descrCor <- cor(datTrain1)
descrCor
```

- ```verbose``` 表示是否输出建议
- ```names``` 表示是否输出变量名（否则输出的是变量的编号）

```{r}
# 超过 0.75 的简单相关系数就认为存在高度相关
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75,, names = F, verbose = T)
highlyCorDescr
# 按照建议删除相关的列
filteredTrain <- datTrain1[, -highlyCorDescr]
```

## 标准化

- 量纲不同，放置某项权重过高
- 利用训练集的均值和方差对测试集进行标准化

```{r}
preProcValues <- preProcess(datTrain, method = c("center", "scale"))
trainTransformed <- predict(preProcValues, datTrain)
testTransformed <- predict(preProcValues, datTest)
```


# 模型训练与调参

参数池 > 参数组合 > 目标函数

- 手动搜索
- 网格搜索：有标准：把所有符合标准的参数放进参数池再进行搜素
- 随机搜索：没有标准，随机组合参数


```{r}
setwd("C:/Users/lenovo/Desktop/RYaan/R/class_software/Notes")
dat0 <- read.csv("../Data/相亲数据.csv", encoding = 'GBK2312')
head(dat0)
# 缺失值处理
nrow(dat0)
dat = na.omit(dat0)
# 转化数据类型
dat$'决定' <- factor(dat$'决定', levels = c(0,1), labels = c("拒绝", "接收"))
dat$'性别' <- factor(dat$'性别', levels = c(0,1), labels = c("女", "男"))
dat$'种族' <- factor(dat$'种族', levels = c(1, 2, 3, 4, 5, 6), labels = c("非洲裔", "欧洲裔", "拉丁裔", "亚裔", "印第安土著", "其他"))
dat$'从事领域' <- factor(dat$'从事领域', levels = 1:18, labels = c("法律","数学","社会科学或心理学", "医学或药物学或生物技术","工程学","写作或新闻", "历史或宗教或哲学","商业或经济或金融","教育或学术", "生物科学或化学或物理","社会工作","大学在读或未择方向", "政治学或国际事务","电影","艺术管理","语言","建筑学","其他"))
dat$'对方决定' <- factor(dat$'对方决定', levels = c(0, 1), labels = c("拒绝","接收"))
dat$'对方种族' = factor(dat$'对方种族', levels = c(1,2,3,4,5,6), labels = c("非洲裔","欧洲裔","拉丁裔","亚裔","印第安土著","其他"))
dat$'是否同一种族' = factor(dat$'是否同一种族', levels = c(0,1), labels = c("非同一种族","同一种族"))
# 数据分割
set.seed(1234)#设置随机种子
trainIndex <- createDataPartition(dat$'决定', p = 0.8, list = FALSE, times = 1)
datTrain = dat[trainIndex, ]
datTest <- dat[-trainIndex, ]
# 标准化处理
preProcValues <- preProcess(datTrain, method = c("center", "scale"))
dat.train <- predict(preProcValues, datTrain)
dat.test <- predict(preProcValues, datTest)
```


## 网格调参

- 设计随机种子保持可重复性
- 利用 ```trainControl()``` 函数设置模型训练时用到的参数
- 利用网格搜索的参数池，也就是设置参数的选择范围
- 利用 ```train()``` 函数来进行模型训练及得到最优的参数组合


```{r}
set.seed(825)
# crossvalidation 交叉验证 mehod = "cv"
fitControl <- trainControl(method = "cv", number = 10, classProbs = TRUE, summaryFunction = twoClassSummary)
gbmGrid <- expand.grid(interaction.depth = c(1, 5), n.trees = (1:20)*3, shrinkage = 0.1, n.minobsinnode = 20)
nrow(gbmGrid)

gbmFit2 <- train(决定 ~., data = dat.train, method = "gbm", trControl = fitControl, verbose = FALSE, tuneGrid = gbmGrid, metric = 'ROC')
gbmFit2
# 画图
trellis.par.set(caretTheme())
plot(ggbmFit2)
```



## 随机调参
- ```trainControl()``` 函数设定模型训练的参数search = ramdom
- 不用设置参数组合，直接进行训练
- 不用设置 tuneGrid 参数，但是要设置 tuneLength（随机搜索多少组）
- 利用 train 函数来进行

```{r}
set.seed(825)
fitControl = trainControl(method = "cv",number = 10,classProbs = TRUE,
                          summaryFunction = twoClassSummary,search = "random")
gbmFit3 = train(决定 ~ ., data = dat.train, method = "gbm", trControl = fitControl, 
                 verbose = FALSE, metric = "ROC",tuneLength = 10)
gbmFit3
```


# 模型的预测及评价

- ```predict()``` 函数
- 混淆矩阵 ```cconfusionMatrix()``` 函数

```{r}
##网格搜索
data.predict = predict(gbmFit2, newdata = dat.test)
confusionMatrix(data.predict,dat.test$决定)
##随机搜索
data.predict = predict(gbmFit3, newdata = dat.test)
confusionMatrix(data.predict,dat.test$决定)
```


# 模型的训练与集成

## 模型训练

- 利用不同模型提高预测精度

### 逻辑回归

- ```method``` 参数应为 “glm”

```{r}
fit1 = train(决定 ~ ., data = dat.train, method = "glm",family="binomial")  #训练模型
pstate1 = predict(fit1, newdata = dat.test)  #在测试集上预测
confusionMatrix(pstate1, dat.test$决定)      #利用混淆矩阵评估模型
```


### 决策树

- ```method = 'rpart'```


```{r}
fit2 = train(决定 ~ ., data = dat.train, 
               method = "rpart")  #训练模型
pstate2 = predict(fit2, newdata = dat.test) #在测试集上预测
confusionMatrix(pstate2, dat.test$决定) #利用混淆矩阵评估模型
```

### 随机森林

- ```method = 'rf'```
- 多棵决策树，决策单元时决策树

```{r}
set.seed(1234)
fit3 = train(决定 ~ ., data = dat.train, method = "rf")  #训练模型
pstate3 = predict(fit3, newdata = dat.test) #在测试集上预测
confusionMatrix(pstate3, dat.test$决定) #利用混淆矩阵评估模型
```

```{r}
results <- data.frame(pstate1, pstate2, pstate3)
results <- apply(results, 2, as.characte)
major_results = apply(results,X = 1, function(x){
  tb = sort(table(x), decreasing = T)
  if(tb[1] %in% tb[2]){
    return(sample(c(names(tb)[1], names(tb)[2]), 1))
  }else{ return(names(tb)[1])}
})
major_results <- factor(major_results, levels = c("拒绝", "接受"))
confusionMatrix(major_results, dat.test$决定)
```


## 模型集成

### 投票法

- 适用于分类问题
- 有可能有猪队友拉后腿

```{r}
results = data.frame(pstate1, pstate2,  pstate3)
results = apply(results,2,as.character)
major_results = apply(results, 1, function(x){
  tb = sort(table(x),decreasing = T)
  if(tb[1] %in% tb[2]){
    return(sample(c(names(tb)[1],names(tb)[2]),1))
  }else{ return(names(tb)[1]) }
})
major_results = factor(major_results,levels = c("拒绝","接收"))
confusionMatrix(major_results, dat.test$决定)
```



### 堆叠继承法

- stacking

```{r}
set.seed(1234)
combPre = data.frame(pstate1, pstate2, pstate3,决定 = dat.test$决定)
combfit = train(决定~., method = "rf", data = combPre)
combpstate = predict(combfit, newdata = dat.test)
confusionMatrix(combpstate, dat.test$决定)
```

### AdaBoost

```{r}
set.seed(1234)
fit4 = train(决定 ~ ., data = dat.train, 
               method = "gam")  #训练模型
pstate4 = predict(fit4, newdata = dat.test) #在测试集上预测
confusionMatrix(pstate4, dat.test$决定) #利用混淆矩阵评估模型
```





























# 待解决

- ```createFolds()``` 中的参数 ```returnTrain``` 是干嘛的？
- 不理解 ```expand.grid()``` 等函数调参函数的使用





