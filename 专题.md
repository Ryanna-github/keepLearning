# Modul 类

> 所在位置：torch.nn

## 主要函数用法

```{python}
import torch
from torch import nn

class MLP(nn.Module):
    def __init__(self):
        # 对父类进行初始化方法
        super(MLP, self).__init__()
        self.hidden = nn.Linear(input_num, hidden_num)
        # 隐藏层的激活函数
        self.act = nn.ReLU()
        self.output = nn.Linear(hidden_num, output_num)
        
    # 向前传播算法
    def forward(self, x):
        a = self.act(self.hidden(x))
        return self.output(a)
```

## 子类 `Sequential`

```{python}
class MySequential(nn.Module):
    from collections import OrderedDict
    def __init__(self, *args):
        super(MySequential, self).__init__()
        if(len(args) == 1 and isinstance(args[0], OrderedDict)):
            for key, module in args[0].items():
                self.add_module(key, module)
        else:
            for idx, module in enumerate(args):
                self.add_module(str(idx), module)
    
    def forward(self, input):
        for module in self._modules.values():
            input = module(input)
        return input
```

- `add_module` 可以依次添加模块
- 任何 `Module` 子类都可以使用 `_modules` 查看其中的模块细节信息

```{python}
# 传入 OrderedDict 情况
from collections import OrderedDict
od = OrderedDict([
    ("hidden", nn.Linear(input_num, hidden_num)),
    ("act", nn.ReLU()),
    ("output", nn.Linear(hidden_num, output_num))
])
net = MySequential(od)
# 传入多个 Module 情况
# 没有命名则自动从数字0开始命名
net = MySequential(nn.Linear(input_num, hidden_num),
                  nn.ReLU(),
                  nn.Linear(hidden_num, output_num))
```



## 子类 `ModuleList`

```{python}
# 初始化
net = nn.ModuleList([nn.Linear(input_num, hidden_num), nn.ReLU()])
# 添加元素
net.append(nn.Linear(hidden_num, output_num))
```



## 子类 `ModuleDict`

```{python}
# 初始化
net = nn.ModuleDict({
    'linear': nn.Linear(input_num, hidden_num),
    'act': nn.ReLU()
})
# 添加元素
net['output'] = nn.Linear(hidden_num, output_num)
```

---

# Tensor 类

> 基本用法见“Pytorch 学习笔记.md”

## 子类 `Parameter`

- `Tensor` 有的属性其均有
  - `.data`
  - `.grad`
- `nn.Parameter` 定义的张量会被自动添加到参数列表，使用 `nn.paramteres()` 或者 `nn.named_paramters()` 可以进行访问
- 初始化方法：调用 `torch.nn.init` 模块（不记录梯度地更新张量的值）
  - `init.normal_()`
  - `init.constant_()`
  - 自定义函数，注意张量的改变不可以更新其梯度值
    - 方法一：`with torch.no_grad()`
    - 方法二：直接修改 `param.data`

- 共享模型参数